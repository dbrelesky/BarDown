---
phase: 01-data-foundation
plan: 02
type: execute
wave: 2
depends_on:
  - "01-01"
files_modified:
  - Sources/App/Scraper/StatBroadcastScraper.swift
  - Sources/App/Scraper/NCAAAPIScraper.swift
  - Sources/App/Scraper/ScraperScheduler.swift
  - Sources/App/Scraper/HTMLParsers/ScoreboardParser.swift
  - Sources/App/Scraper/HTMLParsers/BoxScoreParser.swift
  - Sources/App/Scraper/ScraperError.swift
  - Sources/App/Scraper/DataReconciler.swift
  - Sources/App/configure.swift
autonomous: true
requirements:
  - DATA-01
  - DATA-03

must_haves:
  truths:
    - "Scraper fetches live game data from StatBroadcast XHR endpoints (or NCAA API fallback) and persists to PostgreSQL"
    - "Scraper runs on a schedule: every 30-60 seconds for conferences with live games, less frequently otherwise"
    - "On scrape failure, the scraper retries and the API continues serving the last successful data"
    - "Scraper covers all 5 Phase 1 conferences: Big East, ACC, Big Ten, Patriot League, Ivy League"
    - "Player-level stats and quarter-by-quarter scores are scraped and stored"
  artifacts:
    - path: "Sources/App/Scraper/StatBroadcastScraper.swift"
      provides: "StatBroadcast data fetching — XHR endpoints discovered during audit"
      contains: "struct StatBroadcastScraper"
    - path: "Sources/App/Scraper/NCAAAPIScraper.swift"
      provides: "NCAA casablanca JSON API integration for scoreboard data"
      contains: "struct NCAAAPIScraper"
    - path: "Sources/App/Scraper/ScraperScheduler.swift"
      provides: "Smart scheduling — adjusts frequency based on live game status"
      contains: "ScraperScheduler"
    - path: "Sources/App/Scraper/HTMLParsers/ScoreboardParser.swift"
      provides: "Parsing StatBroadcast scoreboard HTML/JSON into structured game data"
      contains: "ScoreboardParser"
    - path: "Sources/App/Scraper/HTMLParsers/BoxScoreParser.swift"
      provides: "Parsing StatBroadcast box score data into player stats and quarter scores"
      contains: "BoxScoreParser"
  key_links:
    - from: "Sources/App/Scraper/ScraperScheduler.swift"
      to: "Sources/App/configure.swift"
      via: "Scheduler registered on app boot in configure()"
      pattern: "ScraperScheduler"
    - from: "Sources/App/Scraper/StatBroadcastScraper.swift"
      to: "Sources/App/Models/Game.swift"
      via: "Scraper creates/updates Game records in PostgreSQL"
      pattern: "Game.*save|Game.*create|Game.*update"
    - from: "Sources/App/Scraper/NCAAAPIScraper.swift"
      to: "Sources/App/Models/Game.swift"
      via: "NCAA scraper creates/updates Game records as supplementary source"
      pattern: "Game.*save|Game.*create"
---

<objective>
Build the scraping pipeline that fetches D1 lacrosse game data from StatBroadcast and NCAA APIs and stores it in PostgreSQL.

Purpose: This is the data engine of BarDown. Without the scraper, the database is empty and the API has nothing to serve. The scraper must handle StatBroadcast's JavaScript-rendered pages (by targeting their XHR endpoints directly), fall back to NCAA's JSON API, and run on a smart schedule that's aggressive during live games and conservative otherwise.

Output: A complete scraping system that populates Game, Team, Player, QuarterScore, GameStats, and PlayerGameStats tables with real D1 lacrosse data from 5 conferences.
</objective>

<execution_context>
@/Users/darrenbrelesky/.claude/get-shit-done/workflows/execute-plan.md
@/Users/darrenbrelesky/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-data-foundation/01-RESEARCH.md
@.planning/phases/01-data-foundation/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Audit StatBroadcast and build scoreboard + box score scrapers</name>
  <files>
    Sources/App/Scraper/StatBroadcastScraper.swift
    Sources/App/Scraper/NCAAAPIScraper.swift
    Sources/App/Scraper/HTMLParsers/ScoreboardParser.swift
    Sources/App/Scraper/HTMLParsers/BoxScoreParser.swift
    Sources/App/Scraper/ScraperError.swift
  </files>
  <action>
**CRITICAL FIRST STEP — StatBroadcast Audit:**
Before writing any scraper code, you MUST investigate StatBroadcast's actual data delivery mechanism. This is the single highest-risk unknown in Phase 1.

1. Fetch the raw HTML from `https://stats.statbroadcast.com/scoreboards.php` and conference-specific scoreboards (e.g., `?confid=acc&sport=lcgame&gender=M`) using curl or Vapor's HTTP client
2. Inspect the HTML: look for `<script>` tags containing data URLs, AJAX/XHR endpoint patterns, `StatBroadcastScoreboard` class initialization parameters, `loadPage()` function targets
3. Identify the actual data endpoint URLs — they likely return HTML fragments or JSON that can be fetched directly without a headless browser
4. Document URL patterns for: (a) conference scoreboard data, (b) individual game box score data
5. Identify the correct `confid` values for all 5 Phase 1 conferences by testing URLs

If StatBroadcast XHR endpoints cannot be discovered or are blocked, fall back to NCAA's `data.ncaa.com/casablanca/scoreboard/lacrosse-men/d1/{yyyy}/{mm}/{dd}/scoreboard.json` as the PRIMARY data source (it's less detailed but guaranteed to work for scores).

**StatBroadcastScraper.swift:**
- `scrapeScoreboard(conferenceID:)` → fetches scoreboard data for a conference, returns parsed game data
- `scrapeBoxScore(gameID:)` → fetches individual game detail, returns player stats and quarter scores
- Use `app.client` for HTTP requests (NOT URLSession)
- Parse responses with SwiftSoup if HTML, or Codable if JSON
- Handle errors gracefully: log and return empty/partial results, never crash
- Retry logic: up to 3 attempts with 2-second backoff between retries

**NCAAAPIScraper.swift:**
- `fetchScoreboard(date:)` → fetches all D1 men's lacrosse games for a date from `data.ncaa.com/casablanca/scoreboard/lacrosse-men/d1/{yyyy}/{mm}/{dd}/scoreboard.json`
- Decode with Codable structs matching NCAA JSON structure (see RESEARCH.md for struct definitions)
- Used as supplementary data source for game scores, teams, and schedule metadata
- Test the box score endpoint too: `data.ncaa.com/casablanca/game/{gameID}/boxscore.json` — if it works for lacrosse, integrate it

**ScoreboardParser.swift:**
- Parses StatBroadcast scoreboard response into an array of `ScrapedGame` structs
- `ScrapedGame` contains: homeTeamName, awayTeamName, homeScore, awayScore, status, period, clock, startTime, externalGameID, conferenceID
- CSS selectors / JSON paths determined by the audit step above

**BoxScoreParser.swift:**
- Parses StatBroadcast box score response into `ScrapedBoxScore` struct
- `ScrapedBoxScore` contains: quarterScores (array), homeTeamStats, awayTeamStats, playerStats (array)
- Each player stat line: playerName, number, team, goals, assists, shots, saves, groundBalls, faceoffsWon, faceoffsLost, turnovers, penalties
- Selectors determined by audit

**ScraperError.swift:**
- Enum with cases: networkError, parseError, emptyResponse, rateLimited, unknownConference
- Conforms to Error, CustomStringConvertible for logging
  </action>
  <verify>
    <automated>cd /Users/darrenbrelesky/Documents/claude-code/BarDown && swift build 2>&1 | tail -5</automated>
    <manual>Verify StatBroadcastScraper and NCAAAPIScraper compile. Check that the audit findings are documented in code comments showing discovered URL patterns.</manual>
  </verify>
  <done>StatBroadcast XHR endpoints are discovered and documented. Scrapers compile and have methods for scoreboard and box score data. NCAA API integration provides fallback/supplementary data. ScoreboardParser and BoxScoreParser handle the actual response format discovered during audit.</done>
</task>

<task type="auto">
  <name>Task 2: Build scraper scheduler and data persistence with reconciliation</name>
  <files>
    Sources/App/Scraper/ScraperScheduler.swift
    Sources/App/Scraper/DataReconciler.swift
    Sources/App/configure.swift
  </files>
  <action>
**ScraperScheduler.swift:**
Implement smart scheduling that adjusts scrape frequency based on game state:

- **Live games detected** (any game with status "live" in DB): scrape that conference every 30 seconds
- **Game day active hours** (noon-midnight ET, games scheduled today): scrape every 5 minutes for schedule updates
- **Off hours / no games**: scrape every 30-60 minutes for schedule changes and roster updates
- Use VaporCron or NIO RepeatedTask (whichever is simpler) for the base timer
- The scheduler checks game state in DB to decide which conferences need aggressive polling
- Include a `isRunning` actor/flag to prevent overlapping scrape jobs (per Pitfall 4 in RESEARCH.md)
- Log scrape activity: conference, duration, games found, errors

The scheduler orchestrates both StatBroadcastScraper and NCAAAPIScraper:
- Primary: StatBroadcast (if audit found working endpoints)
- Supplementary: NCAA API (fills gaps, cross-references)
- If StatBroadcast fails for a conference, immediately try NCAA as fallback

**DataReconciler.swift:**
Handles upserting scraped data into PostgreSQL:

- `reconcileGames(scraped:, conferenceID:, on:)` → match scraped games to existing DB records by external ID or team name + date combo
- Create new Game records for unseen games
- Update existing Game records (score, status, period, clock) for known games
- Create/update Team records as discovered (teams are NOT pre-seeded — they're created when first scraped)
- Create/update Player records when box score data is available
- Upsert QuarterScore, GameStats, PlayerGameStats for completed or live games
- Use database transactions for consistency
- Handle team matching: first by statBroadcastID, then by name fuzzy match, then create new

**configure.swift update:**
- Import the Scraper module files
- After migrations, start the ScraperScheduler: `ScraperScheduler(app: app).start()`
- Ensure scheduler only starts in non-test environments
  </action>
  <verify>
    <automated>cd /Users/darrenbrelesky/Documents/claude-code/BarDown && swift build 2>&1 | tail -5</automated>
    <manual>Start the app with `swift run App serve`, check logs for scraper activity. Verify games appear in the database after a scrape cycle runs.</manual>
  </verify>
  <done>Scraper scheduler runs on app boot. Scrapes conferences based on smart scheduling logic. Games, teams, players, and stats are persisted to PostgreSQL. Overlapping scrapes are prevented. Failed scrapes log errors and the API continues serving stale data.</done>
</task>

</tasks>

<verification>
1. `swift build` compiles all scraper code without errors
2. App starts and scraper begins its schedule (visible in logs)
3. After one scrape cycle, games exist in the games table
4. Teams are auto-created with conference relationships
5. For completed games: quarter scores and player stats are populated
6. Scraper handles network errors gracefully (logs, doesn't crash)
7. No data is served from StatBroadcast directly to the client — only through our DB
</verification>

<success_criteria>
- StatBroadcast data endpoints are discovered and documented
- Scraper fetches scoreboard data for all 5 Phase 1 conferences
- Box score scraping provides quarter scores and player stats
- NCAA API provides fallback scoreboard data
- Smart scheduling adjusts frequency based on live game presence
- All scraped data persisted to PostgreSQL via DataReconciler
- Scraper failures are isolated — API keeps serving
</success_criteria>

<output>
After completion, create `.planning/phases/01-data-foundation/01-02-SUMMARY.md`
</output>
